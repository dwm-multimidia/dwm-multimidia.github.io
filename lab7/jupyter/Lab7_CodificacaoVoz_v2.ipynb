{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.17"
    },
    "colab": {
      "name": "Cópia de Lab7_CodificacaoVoz_v11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFr2e224J1Gm"
      },
      "source": [
        "# ESTI019 - Codificação de Sinais Multimídia\n",
        "# Lab8 - Codificação de Voz e Áudio\n",
        "## Profs. Celso S. Kurashima e Mário Minami"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIL_SsSuJ856",
        "outputId": "be03be57-97c5-4c14-ee83-038a2c7e91b2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L-K1mhoJ1Gm"
      },
      "source": [
        "# OBJETIVOS\n",
        "\n",
        "1.   Determinação dos parâmetros LPC\n",
        "2.   Separação Sonora/Surda\n",
        "3.   Espectro e Envoltória LP\n",
        "4.   Estimação da $f_0$ e do Pitch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3A0sgJuJ1Gm"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8X5_XlZJ1Gn"
      },
      "source": [
        "## 1. Separação de uma Estrofe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT5klRg_J1Gn"
      },
      "source": [
        "audio1 = '/content/drive/MyDrive/Colab Notebooks/Entre_Leva_Catia_Falada.wav'\n",
        "print(audio1)\n",
        "v1 , sr1 = librosa.load(audio1)\n",
        "print(type(v1), type(sr1))\n",
        "print(v1.shape, sr1)\n",
        "# Player será aberto! AGUARDE até abrir!\n",
        "IPython.display.Audio(data=v1, rate=sr1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs_7O0l8J1Gn"
      },
      "source": [
        "plt.figure()\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "librosa.display.waveplot(v1, sr=sr1)\n",
        "plt.title('Voz da Cátia' + audio1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8QN85DIJ1Gn"
      },
      "source": [
        "fa = sr1\n",
        "Ts = 0.04\n",
        "Nj = int(Ts*fa)\n",
        "Nseg = int(len(v1)/Nj)\n",
        "Nover = int(Nj*0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV2jWG5EJ1Gn"
      },
      "source": [
        "from scipy import signal\n",
        "hm = signal.get_window('hamming', Nj)\n",
        "plt.plot(hm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBrYIQcQJ1Go"
      },
      "source": [
        "# Só a primeira estrofe\n",
        "v11 = v1[1:64000]\n",
        "plt.figure()\n",
        "fig11, ax11 = plt.subplots(figsize=(15, 3))\n",
        "librosa.display.waveplot(v11, sr=sr1)\n",
        "plt.title('Voz da Cátia Primeira Estrofe' + audio1)\n",
        "print(type(v11), type(sr1))\n",
        "print(v11.shape, sr1)\n",
        "# Player será aberto! AGUARDE até abrir!\n",
        "IPython.display.Audio(data=v11, rate=sr1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMpf3sFqJ1Go"
      },
      "source": [
        "## 2. Cálculo dos Parâmetros LPC, separação U/UV e Espectro + Envoltória LPC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoQsnanDJ1Go"
      },
      "source": [
        "!pip install audiolazy\n",
        "import audiolazy as lz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPkBPq-RJ1Go"
      },
      "source": [
        "Nover = int(Nj*0.5)\n",
        "Nseg1 = int(len(v11)/Nj)\n",
        "p = 10\n",
        "E = []\n",
        "ind_voz = [0]*Nseg1\n",
        "t = np.arange(Nj)\n",
        "for l in range(1, Nseg1-1):\n",
        "    xjan = v1[(l-1)*Nj+Nover:l*Nj+Nover]*hm\n",
        "    x2 = list(np.array(xjan**2))\n",
        "    aux = sum(x2)/Nj\n",
        "    E.append(aux)\n",
        "E1 = 10*np.log10(E)\n",
        "E1min = np.min(E1)\n",
        "E1 = E1 - E1min   # Coloca o ruído de fundo em 0 dB\n",
        "E1max = np.max(E1)\n",
        "# ****************************************************************\n",
        "# OBSERVAÇÃO:\n",
        "# ****************************************************************\n",
        "# ATENÇÃO -> aqui nos arquivos que vocês gravam pode haver diferença\n",
        "# nos limiares de VAD e U/UV\n",
        "# É preciso ajustar ambos olhando para os níveis da \n",
        "# Energia de Tempo Curto E1\n",
        "# ****************************************************************\n",
        "# limiar de atividade VAD\n",
        "E1VAD_lim = E1max - 8\n",
        "print('Limiar VAD ' + str(E1VAD_lim))\n",
        "# Limiar U/UV ajustado para 30% do máximo\n",
        "E1voiced_lim = E1max - 5.3 \n",
        "print('Limiar U/UV ' + str(E1voiced_lim))\n",
        "# indicador de VAD\n",
        "ind_voz = np.where(E1 > E1VAD_lim, 1, 0)\n",
        "ind_voiced = np.where(E1 > E1voiced_lim, 1, 0)\n",
        "tot_voz = np.sum(ind_voz)\n",
        "num_voiced = np.sum(ind_voiced)\n",
        "num_unvoiced = tot_voz - num_voiced\n",
        "linhas_voiced = math.ceil(num_voiced/4)\n",
        "linhas_unvoiced = math.ceil(num_unvoiced/4)\n",
        "\n",
        "print('Sonoros = ' + str(num_voiced) + ' e Surdos = ' + str(num_unvoiced) )\n",
        "fig1, ax1 = plt.subplots(figsize=(15, 3))\n",
        "plt.figure(1)\n",
        "plt.plot(E1)\n",
        "plt.title('Energia da Voz Primeira Estrofe, ' + audio1)\n",
        "\n",
        "# partição das figuras voiced\n",
        "i = 0\n",
        "fig2, ax2 = plt.subplots(figsize=(20, num_voiced + linhas_voiced))\n",
        "plt.title('Segmentos Sonoros (Voiced)', color = 'b')\n",
        "\n",
        "# partição das figuras unvoiced\n",
        "j = 0\n",
        "fig3, ax3 = plt.subplots(figsize=(20, num_unvoiced + linhas_unvoiced))\n",
        "plt.title('Segmentos Surdos (Unvoiced)', color = 'g')\n",
        "\n",
        "for l in range(1, Nseg1-2):\n",
        "    # teste de VAD \n",
        "    if ind_voz[l] == 1:\n",
        "        xjan = v1[(l-1)*Nj+Nover:l*Nj+Nover]*hm\n",
        "        a_filter = lz.lpc.kautocor(xjan, p) \n",
        "        gain_lpc = np.log10(abs(a_filter.error))\n",
        "        w, h = signal.freqz(1,a_filter.numerator,worN=int(Nj/2))\n",
        "        LP = 20 * np.log10(abs(h)) + 10*gain_lpc\n",
        "        # Teste U/UV\n",
        "       \n",
        "        if E1[l] > E1voiced_lim:\n",
        "            \n",
        "            i += 1\n",
        "            ax2 = fig2.add_subplot(linhas_voiced,4,i)\n",
        "            plt.figure(2)          \n",
        "            plt.plot(w, LP, 'b')\n",
        "            plt.ylabel('Amplitude [dB]', color='b')\n",
        "            plt.xlabel('Frequency [rad/sample] - Segmento: ' + str(l), color='b')     \n",
        "            sp = np.fft.fft(xjan)\n",
        "            plt.plot(w, 20*np.log10(abs(sp[0:int(Nj/2)])), 'r')\n",
        "        else:\n",
        "            \n",
        "            j += 1\n",
        "            ax3 = fig3.add_subplot(linhas_unvoiced,4,j)           \n",
        "            plt.figure(3)            \n",
        "            plt.plot(w, LP, 'g')\n",
        "            plt.ylabel('Amplitude [dB]', color='b')\n",
        "            plt.xlabel('Frequency [rad/sample] - Segmento: ' + str(l), color='g')     \n",
        "            sp = np.fft.fft(xjan)\n",
        "            plt.plot(w, 20*np.log10(abs(sp[0:int(Nj/2)])), 'r')    \n",
        "        \n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alHDQSyhIK7c"
      },
      "source": [
        "# 3. Estimação da $f_0$ e do Pitch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRVycX_gN760"
      },
      "source": [
        "f0, voiced_flag, voiced_probs = librosa.pyin(v1, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C5'))\n",
        "times = librosa.times_like(f0)\n",
        "plt.plot(times,f0)\n",
        "plt.ylabel('[Hz]')\n",
        "plt.xlabel('tempo [s]')\n",
        "plt.title('Trajetória da $f_0$ usando algoritmo de pYIN')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwoHrJl_In8v"
      },
      "source": [
        "pitch = 1/f0\n",
        "plt.plot(times,1000*pitch)\n",
        "plt.ylabel('Pitch [ms]')\n",
        "plt.xlabel('tempo [s]')\n",
        "plt.title('Trajetória do Pitch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g1EryUnJJKf"
      },
      "source": [
        "Espectrograma enfatizando a $f_0$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6QJA8dQJDtl"
      },
      "source": [
        "D = librosa.amplitude_to_db(np.abs(librosa.stft(v1)), ref=np.max)\n",
        "fig, ax = plt.subplots()\n",
        "img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax)\n",
        "ax.set(title='Estimação da frequência fundamental por pYIN')\n",
        "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
        "ax.plot(times, f0, label='$f_0$', color='cyan', linewidth=3)\n",
        "ax.legend(loc='upper right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8ZM_-eaJ1Go"
      },
      "source": [
        "## 4. Repita o mesmo procedimento para a sua voz gravada\n",
        "Se houver erro de separação U/UV provavelmente é devido aos níveis de gravação utilizados: ajustar os valores como na OBSERVAÇÃO deste Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIl_pAtqJ1Gp"
      },
      "source": [
        "# 5. No site (relatório)\n",
        "\n",
        "\n",
        "*   Apresente as formas de onda, os espectros sonoros/surdos e os modelados LPC para as GRAVAÇÕES DO GRUPO, analisando os resultados, incluindo todo os áudios utilizados\n",
        "*   Apresente também os espectrogramas dos trechos usados nas suas análises e compare com os modelos LPC obtidos\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWYD4ue5MwJa"
      },
      "source": [
        "\n",
        "\n",
        "> > > > > > -X-X-X-\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhRPyI9NM71P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}